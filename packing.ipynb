{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let make a very useless batch here\n",
    "vec_1 = torch.FloatTensor([[1]])\n",
    "vec_2 = torch.FloatTensor([[1], [2], [3]])\n",
    "vec_3 = torch.FloatTensor([[1], [2]])\n",
    "unsorted_batch = [vec_1, vec_2, vec_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n        [2.],\n        [3.]])\ntensor([[1.],\n        [2.]])\ntensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "# retrieve perm_index by sorting lengths\n",
    "lengths = torch.Tensor([seq.shape[0] for seq in unsorted_batch])\n",
    "_, perm_indices = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "# actually sort the sequences\n",
    "sorted_batch = [unsorted_batch[i] for i in perm_indices]\n",
    "for d in sorted_batch:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]])\ntensor([[1.],\n        [2.],\n        [3.]])\ntensor([[1.],\n        [2.]])\n"
     ]
    }
   ],
   "source": [
    "from dataset import invert_permutation\n",
    "invert_perm_index = invert_permutation(perm_indices)\n",
    "\n",
    "# let's make sure that inverting works\n",
    "for i in invert_perm_index:\n",
    "    print(sorted_batch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1.],\n        [1.],\n        [1.],\n        [2.],\n        [2.],\n        [3.]]), batch_sizes=tensor([3, 2, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The time has come to make a packed batch!\n",
    "# The returned PackedSequence may not make sense to you: that's totally okay\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "packed_batch = pack_sequence(sorted_batch)\n",
    "packed_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(packed_output):  <class 'torch.nn.utils.rnn.PackedSequence'>\ntype(h_n):  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, batch_first=True)\n",
    "# we are feeding in the PackedSequence\n",
    "packed_output, h_n = rnn.forward(packed_batch)\n",
    "\n",
    "# and the output sequence of rnn is also a PackedSequence\n",
    "print(\"type(packed_output): \", type(packed_output))\n",
    "# but the final hidden output is, naturally, just a Tensor \n",
    "print(\"type(h_n): \", type(h_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you are interested in the output sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3993],\n         [-0.1942],\n         [ 0.4553]],\n\n        [[-0.3993],\n         [-0.1942],\n         [ 0.0000]],\n\n        [[-0.3993],\n         [ 0.0000],\n         [ 0.0000]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that's where unpack happens\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "unpacked_output, lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "unpacked_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3993]], grad_fn=<SliceBackward>), tensor([[-0.3993],\n         [-0.1942],\n         [ 0.4553]], grad_fn=<SliceBackward>), tensor([[-0.3993],\n         [-0.1942]], grad_fn=<SliceBackward>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However the unpacked sequences are still both sorted and padded\n",
    "# Remember our invert perm index? Let's \"unsort\" the output\n",
    "# CAVEAT: Always use index_select; Don't use in-place assignment\n",
    "output_seq = unpacked_output.index_select(dim=0, index=invert_perm_index)\n",
    "\n",
    "# lastly, we don't want padding in the output\n",
    "# we need to \"unsort\" the lengths as well\n",
    "lengths = lengths.index_select(dim=0, index=invert_perm_index)\n",
    "# slice away the padding\n",
    "output_seq = [o[:l] for o, l in zip(output_seq, lengths)]\n",
    "\n",
    "# And we're done!\n",
    "output_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you are interested in the final hidden output (h_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([1, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1942],\n         [-0.3993],\n         [ 0.4553]]], grad_fn=<IndexSelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is much easier\n",
    "# however, remember that h_n is of shape (num_layer * num_direction, batch_size, hidden_dim)\n",
    "# in our minimal case, it means (1, 3, 1)\n",
    "# as a result, we should do index_select on dim=1\n",
    "print(\"Shape: \", h_n.shape)\n",
    "h_n = h_n.index_select(dim=1, index=invert_perm_index)\n",
    "h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
